{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Function to load and preprocess images from a directory\n",
    "def load_and_preprocess_images_from_folder(folder, target_shape=(256, 256)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, target_shape)\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# Load images and labels from respective folders\n",
    "images_folder = '/kaggle/input/astroid-hunter-dataset/ast/Original Images'\n",
    "labels_folder = '/kaggle/input/astroid-hunter-dataset/ast/Binary Data'\n",
    "\n",
    "X = load_and_preprocess_images_from_folder(images_folder)\n",
    "y = load_and_preprocess_images_from_folder(labels_folder)\n",
    "\n",
    "# Convert multi-class labels to a single binary channel (foreground vs. background)\n",
    "y_binary = np.any(y, axis=-1).astype(np.float32)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_binary_onehot = tf.keras.utils.to_categorical(y_binary, num_classes=2)\n",
    "\n",
    "# Preprocessing\n",
    "X = X.astype('float32') / 255.0\n",
    "\n",
    "# Split dataset into train, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_binary_onehot, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "# Standard U-Net Model\n",
    "def unet(input_size=(256, 256, 3)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    \n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(Conv2DTranspose(512, 2, strides=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    \n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(Conv2DTranspose(256, 2, strides=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    \n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(Conv2DTranspose(128, 2, strides=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    \n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(Conv2DTranspose(64, 2, strides=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(2, 1, activation='softmax')(conv9)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the U-Net model\n",
    "model = unet(input_size=(256, 256, 3))\n",
    "\n",
    "# Train the model with data augmentation\n",
    "batch_size = 8\n",
    "epochs = 10\n",
    "\n",
    "train_datagen = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_datagen = ImageDataGenerator().flow(X_val, y_val, batch_size=batch_size)\n",
    "\n",
    "steps_per_epoch = len(X_train) // batch_size\n",
    "validation_steps = len(X_val) // batch_size\n",
    "\n",
    "model.fit(train_datagen, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=val_datagen, validation_steps=validation_steps)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "accuracy = accuracy_score(np.argmax(y_test, axis=-1).flatten(), y_pred_binary.flatten())\n",
    "precision = precision_score(np.argmax(y_test, axis=-1).flatten(), y_pred_binary.flatten())\n",
    "recall = recall_score(np.argmax(y_test, axis=-1).flatten(), y_pred_binary.flatten())\n",
    "f1 = f1_score(np.argmax(y_test, axis=-1).flatten(), y_pred_binary.flatten())\n",
    "conf_matrix = confusion_matrix(np.argmax(y_test, axis=-1).flatten(), y_pred_binary.flatten())\n",
    "iou = jaccard_score(np.argmax(y_test, axis=-1).flatten(), y_pred_binary.flatten())\n",
    "\n",
    "print(\"Testing Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"IOU:\", iou)\n",
    "\n",
    "# Generate segmentation results on sample images from the testing set\n",
    "num_samples = 5\n",
    "sample_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    img = X_test[idx]\n",
    "    mask_true = y_test[idx]\n",
    "    mask_pred = y_pred[idx]\n",
    "\n",
    "    # Visualize the original image\n",
    "    cv2.imshow(\"Original Image\", img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Visualize true mask\n",
    "    cv2.imshow(\"True Mask\", mask_true)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # Visualize predicted mask\n",
    "    cv2.imshow(\"Predicted Mask\", mask_pred)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
